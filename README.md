# Word2vec

Word2Vec is a group of algorithms that creates word embeddings given a corpus. These word embeddings can then be used in semantic and syntactic analysis.

This model uses the Skip-Gram method, where the model predicts context words given a center word. It also uses negative sampling for efficiency.
